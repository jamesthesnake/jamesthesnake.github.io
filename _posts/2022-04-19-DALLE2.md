At the highest level, DALL-E 2's works very simply:

First, a text prompt is input into a text encoder that is trained to map the prompt to a representation space.
Next, a model called the prior maps the text encoding to a corresponding image encoding that captures the semantic information of the prompt contained in the text encoding.
Finally, an image decoding model stochastically generates an image which is a visual manifestation of this semantic information.
