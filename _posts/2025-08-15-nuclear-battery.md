IN 1970, Surgeons In Paris implanted the first nuclear-powered pacemaker, and over the next five years, at least 1,400 additional people received the devices, mostly in France and the United States. Encased in titanium, the batteries for these devices contained a radioactive isotope—typically about a tenth of a gram of plutonium-238—and could operate for decades without maintenance. The invention provided relief to a population of people who previously needed surgery every few years to change out their pacemaker’s chemical battery.

As time went on, though, the whereabouts of these radioactive tickers became increasingly difficult to track. In the United States, the devices were supposed to be returned to the U.S. Department of Energy for plutonium recovery. But often, that didn’t happen. Doctors changed jobs, manufacturers went out of business, patients died, and families forgot about their loved one’s pacemaker. Too often, the radioactive material landed in crematoriums and coffins.

Uncomfortable with the situation, regulators worldwide nixed the devices. The last known nuclear-powered pacemaker was implanted in 1988. After that, aside from a few specialty uses, such as deep-space probes and Siberian lighthouses, development and deployment of nuclear batteries effectively came to a halt.

Technology never truly dies, and nuclear batteries are no exception. Research grew active again after 2000, although it lacked commercial translation. But over the last year, a host of companies and research groups around the world have announced advances that they say will invigorate the technology and extend its use to robots, drones, sensors, and solar farms, as well as spacecraft and biomedical implants.

The new groups are employing modern, more-exotic technology that goes beyond the designs of the past, allowing them to pursue the finest nuclear batteries ever made. As with the first generation, the allure of nuclear batteries is still their extraordinarily long life-spans: several decades and, with proper fuel choice, possibly centuries. They could also deliver more energy in packages that weigh less than those of chemical batteries.

The question is, who’s going to buy them? Here’s what I’ve observed: The technology works, it has many advantages over chemical batteries, and it can be utilized safely. But what very few companies have been able to do is find a new market for these batteries and make a product that has an impact. Part of the problem is that there is no good solution to the need to track these sources and make sure they are disposed of properly at the end of the battery’s life.

There are more companies working out the challenges now than I’ve ever seen in my career, and that’s good for the field—it helps ground the academic research. And it gives me hope that this could be the moment when nuclear batteries finally flourish.


The term “nuclear batteries” may evoke images of tiny nuclear reactors, but that’s not how they work. Nuclear batteries don’t split atoms with neutron bombardment. Instead, they capture energy in the form of radiation that’s spontaneously released when atomic nuclei decay.

Most research groups developing nuclear batteries are focused on harnessing energy from radioactive isotopes of nickel and hydrogen. In many nuclear battery designs, adjacent semiconductors absorb the radiation released by the radioisotopes’ nuclei and convert it to an electric current, much like a solar cell does. In other designs, thermoelectric devices convert the heat produced by the emitted radiation to electricity. So “radioisotope power source” is a better descriptor than “nuclear battery,” but for ease of language, I’ll use these terms interchangeably.

On the heels of some laboratory successes, researchers are racing to commercialize these devices. The United Kingdom Atomic Energy Authority (UKAEA), Miami-based City Labs, Beijing Betavolt New Energy Technology Co., and China’s Northwest Normal University have all announced advances and funding in semiconductor-based nuclear batteries over the last two years, some with plans to commercialize. Last year, Infinity Power, in San Diego, announced a novel electrochemical approach to converting radioisotope energy.

What markets these batteries will find—if they can be commercialized—will depend largely on cost, safety, and licensing issues. One of the most compelling applications is in uncrewed spacecraft for long-distance missions, which require decades of reliable power. Solar power works for missions close to the sun, but by the time a spacecraft gets to Jupiter, the available solar irradiance drops below 4 percent of that on Earth.

That leaves nuclear fission and radioisotope power as the only viable options for deep-space missions. Fission is ideal for larger power needs in space, like NASA’s proposed 100-kilowatt lunar nuclear reactor. But for lower, onboard power needs, nuclear batteries offer simpler designs and lower mass. The current radioisotope workhorse in space is the radioisotope thermoelectric generator, or RTG, which produces a few hundred watts.



Another good use for nuclear batteries is to supply power in remote locations on Earth. Beginning in the 1970s, for example, the Soviet Union deployed over 1,000 RTGs in northwestern Russia to power its uncrewed lighthouses, radio beacons, and weather stations. Most of these batteries ran on strontium-90, and each weighed about 2,000 kg. The United States has deployed hundreds of similar systems for remote power both on land and on the ocean floor, particularly for remote monitoring sites in the Arctic.
NASA’s two Voyager missions, launched in 1977, each carry three RTGs that weigh about 38 kilograms, including 4.5 kg of plutonium-238. They’re cylindrical and about the size of an office wastebasket. They initially produced 157 watts of electric power, but that drops over time as the plutonium-238 decays. A 157-W Voyager-based RTG that launched in 1977 will produce about 88 W today.


While nuclear batteries have proved successful for space exploration, remote power, and pacemakers, no new uses for these long-lived batteries have emerged. Many devices would benefit from long-lived batteries—imagine a wireless tire pressure sensor that lasts the life of a car, for example. But the risks and costs of opting for a radioactive battery would have to be balanced against the benefits.

Another factor working against the widespread use of nuclear batteries is the need to track the fuel. In just about any country, the sellers and buyers of any such batteries intended for the general public would need to be licensed (see box, “Boy Amasses Large Quantity of Radioactive Material in His Home: A Cautionary Tale”). The buyer also typically takes on the burden of tracking and disposing of the material. Keeping tabs on radioactive material is a necessity, but this adds complexity to applications involving the general public.

One new use where the benefits may outweigh the risks and costs is providing longer-lived power to soldiers—something the U.S. military has explored. Soldiers’ missions often take them to remote or unstable locations where electricity may be unavailable, preventing them from charging their equipment. This forces soldiers to carry batteries, the weight and life of which limit their missions. Small nuclear batteries would provide a lightweight alternative—potentially 1/100 the weight—due to their higher energy density relative to that of chemical batteries. But they would need to be encased to shield soldiers from the radiation, and designed to withstand harsh conditions, which would add weight.

Another potential new use for nuclear batteries is to power autonomous sensors or robots that communicate, move, or fly. One compelling use would be insect-size flying microdrones for civilian and military purposes. But collecting them at the end of their flights might be difficult and would also leave tiny bits of radioactive material littering the landscape.



Let’s turn to the engineering challenges of commercializing a miniature nuclear battery. In general, taking a promising battery technology from the lab to mass production is a complex process that’s more likely to end in failure than success. With nuclear batteries, it involves negotiating a lot of trade-offs between cost, power, safety, and life-span.

First, you have to pick the fuel—that is, an isotope of an element that will release radiation as it decays. Such isotopes emit three types of radiation: gamma rays, beta particles, and alpha particles. Gamma rays are short-wavelength electromagnetic waves that can travel deep into most solids, including living tissue. They’re difficult to contain and capture, so gamma-emitting isotopes are typically avoided.

Pure beta or alpha emitters are a better choice for nuclear batteries. Beta particles are electrons that have an intermediate penetration range in solids. Their decay energies go from a few kiloelectron volts (for tritium, or hydrogen-3) to a few megaelectron volts (for yttrium-90). Alpha particles, by contrast, are emitted at a higher energy than beta particles—typically around 5 MeV—and can’t penetrate a piece of paper. But they can damage semiconductors by creating defects as they collide with the nuclei in the device. This makes alpha emitters best suited for non-semiconductor battery technologies that convert the heat generated by the source fuel into electricity.

Radioisotopes of nickel, carbon, hydrogen, sulfur, promethium, polonium, and plutonium all emit beta or alpha particles and are good options for nuclear batteries (see “Table 1: Radioisotopes Used in Nuclear Batteries”). Which one to choose depends on several factors, including the isotope’s half-life and its decay energy.

For the longest battery life, you’ll want a radioisotope with a long half-life, because the battery’s output power will drop by a factor of two over each half-life. That means a tritium-fueled device will lose half its power every 12 years, while a plutonium-238 battery will lose half its power every 88 years.

If your goal is instead to maximize the battery’s power density—such as for an insect-size microdrone—then you’ll need one with a short half-life. For example, polonium-210 has a half-life of a few months, but a power density of 141 watts per gram, which could give it enough power to carry its payload. The short half-life would mean it would work only for a few months and would completely decay within a couple of years. But for a microdrone that will probably be abandoned somewhere, perhaps that’s a good thing. (Note that these power densities account for thermal power, but there are losses in converting to electricity, so the output power density of any devices created using this fuel will be lower.)

The safest nuclear battery fuels are tritium and nickel-63, because they produce low-energy beta particles that are easier to shield and less damaging to semiconductors than alpha particles. Pure tritium can be challenging to work with because it’s a gas at room temperature. It can be converted into a metal hydride, but this process, which involves mixing it with stable isotopes, decreases its energy density. Another design consideration is that the lower penetration depth of these safer, low-energy beta emitters requires that the sources be made very thin, or else the particles will never reach the battery’s semiconductor.

What about supply and cost? All radioisotopes are expensive to procure and are typically only available in small quantities. Just about any of them can be made during nuclear fission by placing a dedicated target material in the reactor core. They can also be made using particle accelerators. Some types of radioisotopes can be obtained from spent nuclear fuel. But none of these options is simple or inexpensive, because every step requires the handling of radioactive materials.

One gram of tritium costs about US $30,000 and will produce a thermal power of about 0.3 W, which would in turn typically produce an electric power of only a few milliwatts. The supply of plutonium-238 is so limited that NASA must set its launch schedule according to the availability of the fuel. As a result, NASA is pursuing americium-241 as an alternative. It’s unclear how these costs would change if the market for these materials grows substantially.

After choosing a fuel, you have to select a conversion technology. Early radioisotope power sources developed in the 1950s simply collected the charged decay particles, producing an electric potential difference between the collector and the source—that is, a voltage—that could then be tapped to produce electricity. The current in these designs was inherently low, and so the battery had to be run at a high voltage (in the kilovolts) to achieve a reasonable conversion efficiency, which proved too challenging.

To get around this problem, you can use a semiconductor to turn each charged particle emitted by the source into thousands of charge carriers, allowing the device to run at a few volts instead of a few kilovolts. The physics of such a device is essentially that of a solar cell, except that the source of the radiation is from a radioisotope instead of the sun. When the radioisotope is a beta-particle emitter, we call the device “betavoltaic.”

Under development since the 1950s, betavoltaic batteries feature a radioactive emitter and a silicon-diode absorber. As the emitter naturally decays, electrons (in the form of beta particles) strike the absorber. This creates a cascade of electron-hole pairs, which occur when electrons are removed from their original position, leaving a “hole” that generates a small but stable supply of electric current. This process is similar to that of a solar cell, where light produces the electron-hole pairs.

Betavoltaic batteries with silicon diodes have conversion efficiencies of a few percent, and up to 10 percent with silicon carbide, and can typically operate at around 1 volt. Some models indicate that this efficiency can be as high as 23.5 percent. Recent research on betavoltaics uses diamond semiconductors, which offer even higher conversion efficiencies due to their higher bandgap.

Betavoltaics are solid-state, simple, and relatively inexpensive, so they offer an ideal way to produce a low-power option (less than about a milliwatt) for nuclear batteries. They can be used to create higher-power devices, but in those cases it’s often better to switch to an alpha emitter to achieve a higher power density. However, because the alpha particles will damage a semiconductor, their use generally requires a conversion option that relies on heat converted to electricity.

For example, NASA uses thermoelectric conversion in its RTGs, which have been used to power not only Voyager 1 and 2, but also two Mars rovers and over 40 other NASA missions. If you’ve seen the movie The Martian, you may recall how Matt Damon’s character, trapped alone on Mars, used an RTG: He needed a heat source to stay warm while traveling in a rover, so he dug up an old RTG from a previous mission and placed it inside his vehicle.

To convert the heat to electricity, the RTGs employ a series of thermocouples, which consist of a junction of two dissimilar conductors. These components produce a potential in the presence of a temperature gradient (via what’s known as the Seebeck effect). The pacemakers of the 1970s also relied on thermoelectric conversion, albeit on a smaller scale.

Other, more-exotic conversion techniques include radioluminescent conversion, thermionic conversion, and thermophotovoltaic conversion (see sidebar, “Three Other Ways to Convert Radioactivity Into Electricity”), all of which work well in the lab but require higher operating temperatures or have degradation issues. Most companies are focused on developing betavoltaic technology because it permits the use of the safer beta emitters.



