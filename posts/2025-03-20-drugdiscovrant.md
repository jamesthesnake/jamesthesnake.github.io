A good general rule of thumb I have for any AI in drug discovery paper is a simple one: I want to see the actual structures predicted and not just the attendant statistics (which of course are critical). CADD scientists and medicinal chemists live and thrive by the quality of chemical matter, not the technologies used to create it. If your method is effective, it should be reasonable to expect that it can design efficacious and novel compounds that stand scrutiny by medicinal chemists who have a refined visual sensibility informed by intuition and experience.

A good example of this is techniques that do ADME prediction like the one described in the paper below. I am not singling out this paper or saying it’s wrong, just that it’s representative of too many similar papers that I have seen. If I just have a table of statistics saying that a technique is better by some amount than the existing benchmarks - and the accuracy of real-world benchmarks is a whole different topic of discussion - but there are no predicted molecules which I can evaluate for things like metabolic soft spots or functional groups that can lead to toxicity liabilities, as a medicinal chemist I am unable to evaluate how good or bad the technique is. 

In my experience, an important reason for medicinal chemists being unable to evaluate such papers is because there’s a disconnect between the statistics and the kind of structure-enabled results that are necessary to evaluate real-world compound design. This leads many of them to be skeptical, sometimes overly so, of AI. That does both fields a disservice.

